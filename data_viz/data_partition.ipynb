{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b9cc63-2ad8-4d88-8735-e11915052c88",
   "metadata": {},
   "source": [
    "# data partition notebook\n",
    "use this notebook to configure and create dataset with training, testing, and validation partitions. allows one to not use data directly from scrape. partition workflow:\n",
    "- select garage, date range and output path for dataset\n",
    "- generates data and saves entire data set as bulk set\n",
    "- configure parameters to save partitioned dataset\n",
    "- saves partitioned dataset\n",
    "\n",
    "datasets are saved as `.pkl` or pickle files to easy load back into python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e1729-cc46-41f5-8420-2769bbf086c2",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d27149-0a52-4072-a310-55c11b98c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../lib\")))\n",
    "\n",
    "from data_load import load_data, load_week_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc785625-5dfa-4377-9cfa-2bf5161e8274",
   "metadata": {},
   "source": [
    "## define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3ee101-e471-4a71-8116-ba9cb5aecf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "GARAGE = \"North Garage\"\n",
    "DATE_START = pd.to_datetime(\"2025-01-01 12:00:00 AM\")\n",
    "DATE_END = pd.to_datetime(\"2025-06-01 12:00:00 AM\")\n",
    "\n",
    "# path where data will be saved\n",
    "OUTPUT_PATH = \"../datasets/\"\n",
    "ENABLE_BULKSET_SAVE = False\n",
    "RAND_WEEKS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e03166-4e08-48b0-bca7-36f24f948578",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d99bcf0-8ebe-426c-8d30-664d38a6b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates, end_dates, data_by_weeks = load_week_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f9836-496c-4326-b70e-1ece794c64f8",
   "metadata": {},
   "source": [
    "## save bulk set\n",
    "saves data for all garages in given date range to `../datasets/bulkset.pkl`. data saved in format:\n",
    "\n",
    "```\n",
    "data: {\n",
    "    \"North Garage\": [],\n",
    "    \"South Garage\": [],\n",
    "    \"South Campus Garage\": [],\n",
    "    \"West Garage\": []\n",
    "}\n",
    "```\n",
    "\n",
    "where each garage has a list of dataframes, each ith df represents a weeks worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8e67e3-9fe7-4e66-91c4-53a26e30c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = OUTPUT_PATH + \"bulkset.pkl\"\n",
    "\n",
    "if ENABLE_BULKSET_SAVE:\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(data_by_weeks, f)\n",
    "        print(f\"saved data for each garage in {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2c115-2e0a-414f-af7e-e0bc1307413b",
   "metadata": {},
   "source": [
    "## save bulk set for specific garage\n",
    "saves a list of dataframes (each df represents one week of data) to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6ba45f-fe36-41eb-8092-a26755c72f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded for North Garage from 2025-01-01 00:00:00-2025-06-01 00:00:00 contains 8 weeks of data\n",
      "data starts on week of 2025-02-13 16:57:00\n",
      "data ends on week of 2025-04-14 00:13:00\n",
      "wrote North Garage data to ../datasets/North_Garage/2025-02-13_2025-04-14_set.pkl\n"
     ]
    }
   ],
   "source": [
    "garage_data_by_weeks = data_by_weeks[GARAGE]\n",
    "\n",
    "data_start = str(garage_data_by_weeks[0].iloc[0][\"timestamp\"])\n",
    "data_end = str(garage_data_by_weeks[-1].iloc[0][\"timestamp\"])\n",
    "print(f\"data loaded for {GARAGE} from {str(DATE_START)}-{str(DATE_END)} contains {len(garage_data_by_weeks)} weeks of data\")\n",
    "print(f\"data starts on week of {data_start}\")\n",
    "print(f\"data ends on week of {data_end}\")\n",
    "\n",
    "file_path = OUTPUT_PATH + f\"{GARAGE.replace(\" \", \"_\")}/{data_start.split(\" \")[0]}_{data_end.split(\" \")[0]}_set.pkl\"\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(garage_data_by_weeks, f)\n",
    "    print(f\"wrote {GARAGE} data to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91100b49-b537-429a-90be-b6c4c4330fde",
   "metadata": {},
   "source": [
    "## save partitioned dataset\n",
    "configure size of each parition by specifying number of weeks each parition should have. by default each parition does not overlap. weeks are chosen randomly to put in each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037152d8-2cc2-4447-b9e9-cdd57a89cd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "training info:\n",
      "\n",
      "chosen weeks starting at: \n",
      "[Timestamp('2025-02-24 00:21:00'), Timestamp('2025-04-14 00:13:00'), Timestamp('2025-02-17 00:37:00'), Timestamp('2025-02-13 16:57:00'), Timestamp('2025-03-17 01:09:00')]\n",
      "\n",
      "set preview:\n",
      "              timestamp   garage name  fullness\n",
      "746 2025-02-24 00:21:00  North Garage         5\n",
      "742 2025-02-24 00:21:00  North Garage         5\n",
      "             timestamp   garage name  fullness\n",
      "74 2025-04-14 00:13:00  North Garage         5\n",
      "78 2025-04-14 06:29:00  North Garage         6\n",
      "             timestamp   garage name  fullness\n",
      "34 2025-02-17 00:37:00  North Garage         5\n",
      "30 2025-02-17 00:37:00  North Garage         5\n",
      "            timestamp   garage name  fullness\n",
      "2 2025-02-13 16:57:00  North Garage        69\n",
      "6 2025-02-13 17:17:00  North Garage        62\n",
      "              timestamp   garage name  fullness\n",
      "538 2025-03-17 01:09:00  North Garage         5\n",
      "558 2025-03-17 09:01:00  North Garage        70\n",
      "\n",
      "\n",
      "test info:\n",
      "\n",
      "chosen weeks starting at: \n",
      "[Timestamp('2025-03-03 07:12:00'), Timestamp('2025-03-10 06:45:00')]\n",
      "\n",
      "set preview:\n",
      "              timestamp   garage name  fullness\n",
      "226 2025-03-03 07:12:00  North Garage        13\n",
      "222 2025-03-03 07:12:00  North Garage        13\n",
      "               timestamp   garage name  fullness\n",
      "1126 2025-03-10 06:45:00  North Garage         7\n",
      "1122 2025-03-10 06:45:00  North Garage         7\n",
      "\n",
      "\n",
      "validation info:\n",
      "\n",
      "chosen weeks starting at: \n",
      "[Timestamp('2025-03-24 07:49:00')]\n",
      "\n",
      "set preview:\n",
      "               timestamp   garage name  fullness\n",
      "1498 2025-03-24 07:49:00  North Garage        24\n",
      "1494 2025-03-24 07:49:00  North Garage        24\n",
      "wrote data to ../datasets/North_Garage/2025-02-13_2025-04-14_partitioned_r.pkl\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZE = 5\n",
    "TEST_SIZE = 2\n",
    "VALIDATION_SIZE = 1\n",
    "\n",
    "# specific starting weeks to last weeks to choose from if choosing weeks deterministically\n",
    "DIRECTION = \"last weeks\"\n",
    "\n",
    "partitioned_data = {\n",
    "    \"training\": [],\n",
    "    \"test\": [],\n",
    "    \"validation\": []\n",
    "}\n",
    "\n",
    "def choose_rand_weeks(num_weeks, set_type):\n",
    "    chosen_weeks = []\n",
    "    for i in range(num_weeks):\n",
    "        rand_ind = random.randint(0, len(garage_data_by_weeks)-1)\n",
    "        chosen_weeks.append(garage_data_by_weeks[rand_ind].iloc[0][\"timestamp\"])\n",
    "        partitioned_data[set_type].append(garage_data_by_weeks.pop(rand_ind))\n",
    "    print(f\"\\n\\n{set_type} info:\\n\")\n",
    "    print(f\"chosen weeks starting at: \\n{chosen_weeks}\\n\")\n",
    "    print(\"set preview:\")\n",
    "    for df in partitioned_data[set_type]:\n",
    "        print(df.head(2))\n",
    "\n",
    "def choose_deterministic_weeks(num_weeks, set_type, direction):\n",
    "    remove = 0\n",
    "    if direction == \"last weeks\":\n",
    "        remove = -1\n",
    "    chosen_weeks = []\n",
    "    for i in range(num_weeks):\n",
    "        chosen_weeks.append(garage_data_by_weeks[remove].iloc[0][\"timestamp\"])\n",
    "        partitioned_data[set_type].append(garage_data_by_weeks.pop(remove))\n",
    "    print(f\"\\n\\n{set_type} info:\\n\")\n",
    "    print(f\"chosen weeks starting at: \\n{chosen_weeks}\\n\")\n",
    "    print(\"set preview:\")\n",
    "    for df in partitioned_data[set_type]:\n",
    "        print(df.head(2))\n",
    "\n",
    "if RAND_WEEKS:\n",
    "    choose_rand_weeks(TRAINING_SIZE, \"training\")\n",
    "    choose_rand_weeks(TEST_SIZE, \"test\")\n",
    "    choose_rand_weeks(VALIDATION_SIZE, \"validation\")\n",
    "    file_path = file_path.replace(\"_set\", \"_partitioned_r\")\n",
    "else:\n",
    "    choose_deterministic_weeks(TRAINING_SIZE, \"training\", DIRECTION)\n",
    "    choose_deterministic_weeks(TEST_SIZE, \"test\", DIRECTION)\n",
    "    choose_deterministic_weeks(VALIDATION_SIZE, \"validation\", DIRECTION)\n",
    "    file_path = file_path.replace(\"_set\", f\"_partitioned_d_{DIRECTION.split(\" \")[0]}\")\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(partitioned_data, f)\n",
    "    print(\"wrote data to \" + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffe4ce-6be9-4a66-a9c7-4546b7678c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
